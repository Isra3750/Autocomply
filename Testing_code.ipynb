{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpaCy is like the Swiss Army knife of NLP, while Transformers is more akin to a sledge hammer.\n",
    "\n",
    "SpaCy is fast and lightweight. Transformers (ie. Sentence transformer) let’s you use state of the art stuff, but the trade off is usually in terms of slower runtime at inference and larger memory usage.\n",
    "\n",
    "Another important distinction is that SpaCy has tools for more linguistics-focused tasks, such as dependency parsing, and annotations. While transformers has tools for tasks that span beyond just NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# the problem with fuzz is that it does not capture sematic meaning -> good ratio can be very bad since wording is key in TORs\n",
    "str1 = 'Oracle             database'\n",
    "str2 = 'Oracle database'\n",
    "display(fuzz.token_sort_ratio(str1, str2)) # token based -> order does not matter as much as long as words are the same\n",
    "display(fuzz.ratio(str1, str2)) # Order matters -> whitespace also effect the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.8878823518753052\n"
     ]
    }
   ],
   "source": [
    "# test using sentence models -> pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# load a pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Define the two sentences\n",
    "sentence1 = 'I want to really eat some ice cream at the store'\n",
    "sentence2 = 'I want to really not eat some ice cream at the storesssssssssss'\n",
    "\n",
    "# Generate embeddings for each sentence\n",
    "embedding1 = model.encode(sentence1, convert_to_tensor=True)\n",
    "embedding2 = model.encode(sentence2, convert_to_tensor=True)\n",
    "\n",
    "# Compute cosine similarity between the embeddings\n",
    "cosine_score = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "print(\"Cosine similarity:\", cosine_score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Desktop\\Autocomply\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lang': 'en', 'name': 'core_web_trf', 'version': '3.8.0', 'description': \"English transformer pipeline (Transformer(name='roberta-base', piece_encoder='byte-bpe', stride=104, type='roberta', width=768, window=144, vocab_size=50265)). Components: transformer, tagger, parser, ner, attribute_ruler, lemmatizer.\", 'author': 'Explosion', 'email': 'contact@explosion.ai', 'url': 'https://explosion.ai', 'license': 'MIT', 'spacy_version': '>=3.8.0,<3.9.0', 'spacy_git_version': '5010fcbd3', 'vectors': {'width': 0, 'vectors': 0, 'keys': 0, 'name': None, 'mode': 'default'}, 'labels': {'transformer': [], 'tagger': ['$', \"''\", ',', '-LRB-', '-RRB-', '.', ':', 'ADD', 'AFX', 'CC', 'CD', 'DT', 'EX', 'FW', 'HYPH', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NFP', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', 'XX', '``'], 'parser': ['ROOT', 'acl', 'acomp', 'advcl', 'advmod', 'agent', 'amod', 'appos', 'attr', 'aux', 'auxpass', 'case', 'cc', 'ccomp', 'compound', 'conj', 'csubj', 'csubjpass', 'dative', 'dep', 'det', 'dobj', 'expl', 'intj', 'mark', 'meta', 'neg', 'nmod', 'npadvmod', 'nsubj', 'nsubjpass', 'nummod', 'oprd', 'parataxis', 'pcomp', 'pobj', 'poss', 'preconj', 'predet', 'prep', 'prt', 'punct', 'quantmod', 'relcl', 'xcomp'], 'attribute_ruler': [], 'lemmatizer': [], 'ner': ['CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART']}, 'pipeline': ['transformer', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner'], 'components': ['transformer', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner'], 'disabled': [], 'performance': {'token_acc': 0.9986194413, 'token_p': 0.9956819193, 'token_r': 0.9957659295000001, 'token_f': 0.9957239226000001, 'tag_acc': 0.9811806415000001, 'sents_p': 0.9411328038000001, 'sents_r': 0.8363348506, 'sents_f': 0.8856444289000001, 'dep_uas': 0.9518836807000001, 'dep_las': 0.9384315055, 'dep_las_per_type': {'prep': {'p': 0.9229283442, 'r': 0.92464428, 'f': 0.9237855153000001}, 'det': {'p': 0.9902952210000001, 'r': 0.9902144663, 'f': 0.990254842}, 'pobj': {'p': 0.9839824121, 'r': 0.9842528961, 'f': 0.9841176355000001}, 'nsubj': {'p': 0.9830732029, 'r': 0.9796276013, 'f': 0.9813473777}, 'aux': {'p': 0.9872967931000001, 'r': 0.9894062138, 'f': 0.9883503779}, 'advmod': {'p': 0.8977991399, 'r': 0.8957597173, 'f': 0.8967782691}, 'relcl': {'p': 0.8814229249000001, 'r': 0.8900580552, 'f': 0.8857194439}, 'root': {'p': 0.9662979734, 'r': 0.8586978033, 'f': 0.9093258819000001}, 'xcomp': {'p': 0.9405833633, 'r': 0.9375448672000001, 'f': 0.9390616574}, 'amod': {'p': 0.9467031535, 'r': 0.9413670230000001, 'f': 0.9440275477000001}, 'compound': {'p': 0.9513269402000001, 'r': 0.9502673201, 'f': 0.9507968349}, 'poss': {'p': 0.9871330921, 'r': 0.9883252818, 'f': 0.9877288272}, 'ccomp': {'p': 0.8349658104000001, 'r': 0.9201629328, 'f': 0.8754965604}, 'attr': {'p': 0.9531897266, 'r': 0.9676198486, 'f': 0.9603505843000001}, 'case': {'p': 0.9890547264, 'r': 0.9949949950000001, 'f': 0.9920159681}, 'mark': {'p': 0.949343832, 'r': 0.958399576, 'f': 0.9538502110000001}, 'intj': {'p': 0.6096131301000001, 'r': 0.7619047619, 'f': 0.6773038098}, 'advcl': {'p': 0.8101686254, 'r': 0.7985394107, 'f': 0.8043119848}, 'cc': {'p': 0.8934728332, 'r': 0.8988159311, 'f': 0.8961364178000001}, 'neg': {'p': 0.9633718013, 'r': 0.9633718013, 'f': 0.9633718013}, 'conj': {'p': 0.8668266347, 'r': 0.9094914401, 'f': 0.8876466613}, 'nsubjpass': {'p': 0.9514415781000001, 'r': 0.9646153846000001, 'f': 0.9579831933}, 'auxpass': {'p': 0.9624329159, 'r': 0.9804100228, 'f': 0.9713382984000001}, 'dobj': {'p': 0.9721448468, 'r': 0.9733843334000001, 'f': 0.9727641953}, 'nummod': {'p': 0.9454773869, 'r': 0.9502525253, 'f': 0.9478589421}, 'npadvmod': {'p': 0.8512611276000001, 'r': 0.8152753108, 'f': 0.8328796952}, 'prt': {'p': 0.8621553885000001, 'r': 0.9247311828, 'f': 0.8923476005000001}, 'pcomp': {'p': 0.9290231904, 'r': 0.9257703081, 'f': 0.9273938969000001}, 'expl': {'p': 0.9935760171, 'r': 0.9935760171, 'f': 0.9935760171}, 'acl': {'p': 0.8420767983, 'r': 0.8494271686, 'f': 0.845736013}, 'agent': {'p': 0.9430051813, 'r': 0.9784946237000001, 'f': 0.9604221636}, 'dative': {'p': 0.8163716814, 'r': 0.8463302752, 'f': 0.8310810811}, 'acomp': {'p': 0.9561975769000001, 'r': 0.9306122449, 'f': 0.943231441}, 'dep': {'p': 0.4446337308, 'r': 0.4237012987, 'f': 0.43391521200000005}, 'csubj': {'p': 0.9053254438, 'r': 0.9053254438, 'f': 0.9053254438}, 'quantmod': {'p': 0.874251497, 'r': 0.8302193339, 'f': 0.8516666667}, 'nmod': {'p': 0.8405292479, 'r': 0.7355271176, 'f': 0.7845303867000001}, 'appos': {'p': 0.7903822441, 'r': 0.8342733189, 'f': 0.8117349092}, 'predet': {'p': 0.864, 'r': 0.9270386266, 'f': 0.8944099379}, 'preconj': {'p': 0.6966292135000001, 'r': 0.7209302326, 'f': 0.7085714286}, 'oprd': {'p': 0.8840125392, 'r': 0.8417910448, 'f': 0.8623853211}, 'parataxis': {'p': 0.5677179963, 'r': 0.6637744035, 'f': 0.612}, 'meta': {'p': 0.23178807950000002, 'r': 0.6730769231, 'f': 0.34482758620000004}, 'csubjpass': {'p': 0.8333333333, 'r': 0.8333333333, 'f': 0.8333333333}}, 'ents_p': 0.8972927158, 'ents_r': 0.9012920673, 'ents_f': 0.8992879450000001, 'ents_per_type': {'DATE': {'p': 0.8915700407, 'r': 0.9031746032, 'f': 0.8973348052000001}, 'GPE': {'p': 0.9563739377, 'r': 0.9417015342, 'f': 0.948981026}, 'ORDINAL': {'p': 0.7994011976000001, 'r': 0.8291925466000001, 'f': 0.8140243902000001}, 'ORG': {'p': 0.8959323825000001, 'r': 0.8992576882000001, 'f': 0.8975919555}, 'FAC': {'p': 0.5815217391, 'r': 0.8230769231, 'f': 0.6815286624}, 'QUANTITY': {'p': 0.7558139535, 'r': 0.7142857143, 'f': 0.7344632768}, 'LOC': {'p': 0.8317460317, 'r': 0.8343949045, 'f': 0.8330683625}, 'CARDINAL': {'p': 0.8628266033, 'r': 0.8638525565, 'f': 0.8633392751000001}, 'PERSON': {'p': 0.9248753117, 'r': 0.9683420366000001, 'f': 0.9461096939}, 'NORP': {'p': 0.9324758842, 'r': 0.928, 'f': 0.9302325581}, 'LAW': {'p': 0.5915492958, 'r': 0.65625, 'f': 0.6222222222}, 'TIME': {'p': 0.7635869565000001, 'r': 0.8216374269000001, 'f': 0.7915492958}, 'MONEY': {'p': 0.9289099526000001, 'r': 0.9256198347000001, 'f': 0.9272619752000001}, 'EVENT': {'p': 0.8167938931000001, 'r': 0.6149425287, 'f': 0.7016393443000001}, 'PRODUCT': {'p': 0.627027027, 'r': 0.5497630332, 'f': 0.5858585859000001}, 'WORK_OF_ART': {'p': 0.6582278481, 'r': 0.5360824742, 'f': 0.5909090909}, 'PERCENT': {'p': 0.923566879, 'r': 0.8882082695, 'f': 0.9055425449000001}, 'LANGUAGE': {'p': 1.0, 'r': 0.75, 'f': 0.8571428571}}, 'speed': 4179.5216564566}, 'sources': [{'name': 'OntoNotes 5', 'url': 'https://catalog.ldc.upenn.edu/LDC2013T19', 'license': 'commercial (licensed by Explosion)', 'author': 'Ralph Weischedel, Martha Palmer, Mitchell Marcus, Eduard Hovy, Sameer Pradhan, Lance Ramshaw, Nianwen Xue, Ann Taylor, Jeff Kaufman, Michelle Franchini, Mohammed El-Bachouti, Robert Belvin, Ann Houston'}, {'name': 'ClearNLP Constituent-to-Dependency Conversion', 'url': 'https://github.com/clir/clearnlp-guidelines/blob/master/md/components/dependency_conversion.md', 'license': 'Citation provided for reference, no code packaged with model', 'author': 'Emory University'}, {'name': 'WordNet 3.0', 'url': 'https://wordnet.princeton.edu/', 'author': 'Princeton University', 'license': 'WordNet 3.0 License'}, {'name': 'roberta-base', 'author': 'Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov', 'url': 'https://github.com/pytorch/fairseq/tree/master/examples/roberta', 'license': ''}], 'requirements': ['spacy-curated-transformers>=0.2.2,<1.0.0']}\n"
     ]
    }
   ],
   "source": [
    "# Create spacy nlp object\n",
    "# load en_core_web_md (small model), en_core_web_lg (large model), en_core_web_trf (largest)\n",
    "# pip uninstall en-core-web-lg\n",
    "#nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "print(nlp.meta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statement accuracy rate, compare between sentence transformer vs spacy vs fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 11/11 [00:01<00:00,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([341, 384])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd # for data manipulation\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Import the two excel file - input file and reference file\n",
    "df_main = pd.read_excel('Excel_file/Main.xlsx')\n",
    "df_compare = pd.read_excel('Excel_file/Compare.xlsx')\n",
    "\n",
    "# Import thai compatible model\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Encode all statements from Main.xlsx as a single batch\n",
    "main_statements = df_main['Statement'].tolist()\n",
    "main_embeddings = model.encode(main_statements, convert_to_tensor=True, show_progress_bar=True)\n",
    "print(type(main_embeddings))\n",
    "main_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle # for caching main embeddings\n",
    "\n",
    "# testing pickle, pk1 is pickle file, can be any file type really but pk1 just to demonstrate\n",
    "student_names = ['Kay','Bob','Elena','Jane','Kyle']\n",
    "with open('student_file.pkl', 'wb') as f:  # open a text file\n",
    "    pickle.dump(student_names, f) # serialize the list\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kay', 'Bob', 'Elena', 'Jane', 'Kyle']\n"
     ]
    }
   ],
   "source": [
    "with open('student_file.pkl', 'rb') as f:  # open a text file\n",
    "    list_name = pickle.load(f) # deserialize the list\n",
    "f.close()\n",
    "print(list_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TOR comply number                               TOR comply statement\n",
      "5                4.2  สามารถเลือกทำงานบนระบบปฏิบัติการ Windows หรือ ...\n",
      "6                4.3  เป็นฐานข้อมูลที่มีระบบ Lock ข้อมูลในระดับ Row ...\n",
      "7                4.4  มีคุณสมบัติในการทำ Multi-Version Read Consiste...\n",
      "8                4.5  สามารถทำการเก็บข้อมูลและแสดงผลได้ทั้งภาษาไทยแล...\n",
      "9                4.6  มีการทำงานแบบ Machine Learning เพื่อช่วยเพิ่มป...\n",
      "10               4.7  มีการทำงานแบบ Query Optimization และสามารถทำงา...\n",
      "11               4.8  สามารถรองรับการจัดเก็บข้อมูลในรูปแบบ JSON โดยส...\n",
      "12               4.9       สามารถทำงานในรูปแบบระบบฐานข้อมูลแบบ Graph ได\n",
      "13               4.1  มีเครื่องมือรองรับในการจัดการระบบไฟล์สำหรับไฟล...\n",
      "14               NaN  4.10.1 รองรับการช่วยกระจาย I/O ไปยังดิสก์ข้อมู...\n",
      "15               NaN  4.10.2 รองรับการเพิ่มหรือลดจำนวน disk ได้โดยไม...\n",
      "16               NaN  4.10.3 รองรับการจัดเรียงการกระจายของข้อมูลใหม่...\n",
      "17               NaN  4.10.4 รองรับการ Mirror Resync ข้อมูลระหว่าง D...\n",
      "18              4.11     รองรับการทำงานในลักษณะ Cluster (Active/Active)\n",
      "19              4.12  มาพร้อมกับเครื่องมือในการสร้าง Web Application...\n",
      "20              4.13  สามารถทำงานแบบ Multi-Tenant ได้ไม่น้อยกว่า 3Te...\n",
      "21              4.14  ต้องสนับสนุน เน็ตเวิร์คโปรโตคอลแบบ TCP/IP เป็น...\n",
      "22              4.15  มีลิขสิทธิ์ใช้งานถูกต้องตามกฎหมายแบบไม่จำกัดจำ...\n"
     ]
    }
   ],
   "source": [
    "# selecting excel test\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def excel_cell_to_indices(cell_str):\n",
    "    \"\"\"\n",
    "    Converts an Excel cell address (e.g., \"A5\") to zero-based (row, column) indices.\n",
    "    \"\"\"\n",
    "    match = re.match(r\"([A-Za-z]+)([0-9]+)\", cell_str)\n",
    "    if not match:\n",
    "        raise ValueError(\"Invalid cell format: \" + cell_str)\n",
    "    col_str, row_str = match.groups()\n",
    "    # Convert letters to a zero-based column index:\n",
    "    col_idx = 0\n",
    "    for char in col_str.upper():\n",
    "        col_idx = col_idx * 26 + (ord(char) - ord('A') + 1)\n",
    "    col_idx -= 1  # adjust to zero-based index\n",
    "    row_idx = int(row_str) - 1  # adjust to zero-based index\n",
    "    return row_idx, col_idx\n",
    "\n",
    "def slice_excel_by_cells(df, num_start, num_end, stmt_start, stmt_end):\n",
    "    \"\"\"\n",
    "    Extracts two series from the DataFrame based on provided Excel cell ranges.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame read from the Excel file.\n",
    "        num_start (str): Starting cell for TOR comply numbers (e.g., \"A5\").\n",
    "        num_end (str): Ending cell for TOR comply numbers (e.g., \"A23\").\n",
    "        stmt_start (str): Starting cell for TOR comply statements (e.g., \"B5\").\n",
    "        stmt_end (str): Ending cell for TOR comply statements (e.g., \"B23\").\n",
    "    \n",
    "    Returns:\n",
    "        (pd.Series, pd.Series): Two series, one for numbers and one for statements.\n",
    "    \"\"\"\n",
    "    num_start_row, num_start_col = excel_cell_to_indices(num_start)\n",
    "    num_end_row, _ = excel_cell_to_indices(num_end)  # Column should be same as start for numbers\n",
    "    stmt_start_row, stmt_start_col = excel_cell_to_indices(stmt_start)\n",
    "    stmt_end_row, _ = excel_cell_to_indices(stmt_end)  # Column should be same as start for statements\n",
    "    \n",
    "    # Slicing includes the ending row so add 1 (pandas slicing is end-exclusive)\n",
    "    numbers = df.iloc[num_start_row:num_end_row+1, num_start_col]\n",
    "    statements = df.iloc[stmt_start_row:stmt_end_row+1, stmt_start_col]\n",
    "    return numbers, statements\n",
    "\n",
    "# Example usage:\n",
    "# Read the Excel file (adjust header settings if needed)\n",
    "df = pd.read_excel(\"Excel_file/Unformat_test.xlsx\", header=None)\n",
    "\n",
    "# Dynamically select ranges using Excel cell notation.\n",
    "tor_numbers, tor_statements = slice_excel_by_cells(df, \"A6\", \"A23\", \"B6\", \"B23\")\n",
    "\n",
    "# Combine into a new DataFrame with proper column names\n",
    "result_df = pd.DataFrame({\n",
    "    \"TOR comply number\": tor_numbers,\n",
    "    \"TOR comply statement\": tor_statements\n",
    "})\n",
    "\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Model: 100%|██████████| 1/1 [00:03<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n",
      "Loaded cache file for main embeddings!\n",
      "Encoding compare statements in batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:00<00:00,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarity scores in a single pass...\n",
      "Total time: 3.595 seconds taken\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# single batch code - LLM generated\n",
    "import pandas as pd  # for data manipulation\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Load the two Excel files\n",
    "df_main = pd.read_excel('Excel_file/Main.xlsx')\n",
    "df_compare = pd.read_excel('Excel_file/Compare.xlsx')\n",
    "\n",
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the Sentence Transformer model\n",
    "print(\"Start loading model...\")\n",
    "with tqdm(total=1, desc=\"Loading Model\") as pbar:\n",
    "    model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "    pbar.update(1)\n",
    "print(\"Model loaded!\")\n",
    "\n",
    "# Cache file for main embeddings\n",
    "cache_file = 'main_embeddings.pkl'\n",
    "\n",
    "# Either load cached embeddings or create them if they don't exist\n",
    "if os.path.exists(cache_file):\n",
    "    with open(cache_file, 'rb') as f:\n",
    "        main_embeddings = pickle.load(f)\n",
    "    print(\"Loaded cache file for main embeddings!\")\n",
    "else:\n",
    "    print(\"Start embedding main statements...\")\n",
    "    main_statements = df_main['Statement'].tolist()\n",
    "    main_embeddings = model.encode(main_statements, convert_to_tensor=True, show_progress_bar=True)\n",
    "\n",
    "    with open(cache_file, 'wb') as f:\n",
    "        pickle.dump(main_embeddings, f)\n",
    "    print(\"Created cache file for main embeddings!\")\n",
    "\n",
    "# ---------------------------\n",
    "# BATCH ENCODING IMPROVEMENT\n",
    "# ---------------------------\n",
    "print(\"Encoding compare statements in batch...\")\n",
    "compare_statements = df_compare['Statement'].tolist()\n",
    "compare_embeddings = model.encode(compare_statements, convert_to_tensor=True, show_progress_bar=True)\n",
    "\n",
    "print(\"Computing similarity scores in a single pass...\")\n",
    "# This creates a similarity matrix of shape (len(df_compare), len(df_main))\n",
    "similarity_matrix = util.pytorch_cos_sim(compare_embeddings, main_embeddings)\n",
    "\n",
    "# Find the highest similarity score for each row in df_compare\n",
    "best_scores, best_idxs = similarity_matrix.max(dim=1)\n",
    "\n",
    "# Set a threshold if you want to discard matches below a certain score\n",
    "threshold = 0.1\n",
    "Result = []\n",
    "\n",
    "# Loop through each compare statement once, retrieving the best match\n",
    "for i in range(len(compare_statements)):\n",
    "    score = best_scores[i].item()\n",
    "    idx = best_idxs[i].item()\n",
    "    if score >= threshold:\n",
    "        best_document = df_main.iloc[idx]['Document']\n",
    "        best_statement = df_main.iloc[idx]['Statement']\n",
    "        folder_location = df_main.iloc[idx]['Folder location']\n",
    "        Result.append({\n",
    "            'Number': df_compare.iloc[i]['Number'],\n",
    "            'Statement': compare_statements[i],\n",
    "            'Matched Statement': best_statement,\n",
    "            'Matched Document Reference': best_document,\n",
    "            'Similarity Score': score,\n",
    "            'Folder location': folder_location\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "output_df = pd.DataFrame(Result)\n",
    "#print(output_df)\n",
    "\n",
    "# Write the output to Excel with XlsxWriter\n",
    "output_file = 'Excel_file/Result.xlsx'\n",
    "with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "    output_df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['Sheet1']\n",
    "\n",
    "    # Format the \"Similarity Score\" column (E) to display as a percentage\n",
    "    percentage_format = workbook.add_format({'num_format': '0.00%'})\n",
    "    worksheet.set_column('E:E', 16, percentage_format)\n",
    "\n",
    "    # Apply conditional formatting based on similarity score\n",
    "    num_rows = len(output_df)\n",
    "    cell_range = f'E2:E{num_rows + 1}'\n",
    "\n",
    "    red_format = workbook.add_format({'bg_color': '#FFC7CE', 'font_color': '#9C0006'})\n",
    "    orange_format = workbook.add_format({'bg_color': '#FFEB9C', 'font_color': '#9C6500'})\n",
    "    green_format = workbook.add_format({'bg_color': '#C6EFCE', 'font_color': '#006100'})\n",
    "\n",
    "    # < 80%: red\n",
    "    worksheet.conditional_format(cell_range, {\n",
    "        'type': 'cell',\n",
    "        'criteria': '<',\n",
    "        'value': 0.8,\n",
    "        'format': red_format\n",
    "    })\n",
    "\n",
    "    # 80% - 95%: orange\n",
    "    worksheet.conditional_format(cell_range, {\n",
    "        'type': 'cell',\n",
    "        'criteria': 'between',\n",
    "        'minimum': 0.8,\n",
    "        'maximum': 0.95,\n",
    "        'format': orange_format\n",
    "    })\n",
    "\n",
    "    # >= 95%: green\n",
    "    worksheet.conditional_format(cell_range, {\n",
    "        'type': 'cell',\n",
    "        'criteria': '>=',\n",
    "        'value': 0.95,\n",
    "        'format': green_format\n",
    "    })\n",
    "\n",
    "    # Adjust column widths\n",
    "    worksheet.set_column('A:A', 8)\n",
    "    worksheet.set_column('B:B', 50)\n",
    "    worksheet.set_column('C:C', 50)\n",
    "    worksheet.set_column('D:D', 60)\n",
    "    worksheet.set_column('F:F', 30)\n",
    "\n",
    "# End time and total time\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total time: {total_time:.3f} seconds taken\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Model: 100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n",
      "Loaded cache file for main embeddings!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 35/35 [00:00<00:00, 54.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 3.965 seconds taken\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Old cold - unbatch processing in loop - slighty slower in redudant testing, faster initials\n",
    "# Import the required lib\n",
    "import pandas as pd # for data manipulation\n",
    "\n",
    "# Sentence Transformers enables the transformation of sentences into vector spaces\n",
    "from sentence_transformers import SentenceTransformer, util # util provides helper function for embeddings such as the function pytorch_cos_sim to compute cosine similarity\n",
    "from tqdm import tqdm # for progress bar\n",
    "import time # for total time\n",
    "import pickle # for caching main embeddings\n",
    "import os\n",
    "\n",
    "# Import the two excel file - input file and reference file\n",
    "df_main = pd.read_excel('Excel_file/Main.xlsx')\n",
    "df_compare = pd.read_excel('Excel_file/Compare.xlsx')\n",
    "\n",
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Import thai compatible model\n",
    "print(\"Start loading model...\")\n",
    "with tqdm(total=1, desc=\"Loading Model\") as pbar:\n",
    "    model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "    pbar.update(1)\n",
    "print(\"Model loaded!\")\n",
    "\n",
    "# Cache file for main embeddings\n",
    "cache_file = 'main_embeddings.pkl'\n",
    "\n",
    "# Use pickle to cache main file embeddings - load if already created, create if not\n",
    "# Note: When excel file is changed, the embeddings will need to be re-created, delete the cache file (main_embeddings.pkl)\n",
    "if os.path.exists(cache_file):\n",
    "    with open(cache_file, 'rb') as f:\n",
    "        main_embeddings = pickle.load(f)\n",
    "    print(\"Loaded cache file for main embeddings!\")\n",
    "else:\n",
    "    # Encode all statements from Main.xlsx as a single batch\n",
    "    print(\"Start embedding main statements...\")\n",
    "    main_statements = df_main['Statement'].tolist()\n",
    "    main_embeddings = model.encode(main_statements, convert_to_tensor=True, show_progress_bar=True)\n",
    "\n",
    "    # Cache the embeddings\n",
    "    with open(cache_file, 'wb') as f:\n",
    "        pickle.dump(main_embeddings, f)\n",
    "    \n",
    "    print(\"Created cache file for main embeddings!\")\n",
    "\n",
    "# Create similarity function - single batch variant\n",
    "def find_match(statement, main_df, threshold=0.2):\n",
    "    \"\"\"\n",
    "    Finds the best match for 'statement' within 'main_df' using sentence-transformers semantic similarity.\n",
    "\n",
    "    Args:\n",
    "        statement (str): The statement from df_compare to match against df_main.\n",
    "        main_df (pd.DataFrame): DataFrame containing 'Statement' and 'Document' columns.\n",
    "        threshold (float): Minimum similarity score required to consider a match valid.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (best_document, best_statement, best_score)\n",
    "            - best_document: The matching 'Document' from df_main\n",
    "            - best_statement: The matched statement from df_main\n",
    "            - best_score: The highest cosine similarity score found\n",
    "    \"\"\"\n",
    "    # Encode the input statement once\n",
    "    embedding_input = model.encode(statement, convert_to_tensor=True)\n",
    "\n",
    "    # Compute similarity to all main embeddings at once (shape: (1, n_main))\n",
    "    similarity_scores = util.pytorch_cos_sim(embedding_input, main_embeddings)[0] # [0] extracts the first row from 2D tensor, this is similarity score for each statement in main_df\n",
    "    # Get the best score and its index\n",
    "    best_score, best_idx = similarity_scores.max(dim=0) # This will get the highest similarity score from the 1D tensor and its index, dim = 0 means row\n",
    "    best_score = best_score.item() # convert pytorch into float, Ex. 0.95\n",
    "    best_idx = best_idx.item() # convert pytorch into float, Ex. 3\n",
    "\n",
    "    # Threshold checking, return none if below threshold, which will skipped the append later\n",
    "    if best_score >= threshold:\n",
    "        # Retrieve the corresponding row from df_main with the best index from before\n",
    "        best_document = main_df.iloc[best_idx]['Document']  # Adjust column name if needed\n",
    "        best_statement = main_df.iloc[best_idx]['Statement']\n",
    "        folder_location = main_df.iloc[best_idx]['Folder location']\n",
    "        return best_document, best_statement, best_score, folder_location\n",
    "    else:\n",
    "        return None, None, best_score, None\n",
    "\n",
    "Result = []\n",
    "# Loop through each row, tqdm for progress bar\n",
    "for _, row in tqdm(df_compare.iterrows(), total=len(df_compare), desc=\"Processing rows\"):\n",
    "    # Use function to find the best match\n",
    "    document, statement, score, location = find_match(row['Statement'], df_main, threshold=0.1)\n",
    "\n",
    "    # If not none, then append to result\n",
    "    if document is not None:\n",
    "        Result.append({\n",
    "            'Number': row['Number'],\n",
    "            'Statement': row['Statement'],\n",
    "            'Matched Statement': statement,\n",
    "            'Matched Document Reference': document,\n",
    "            'Similarity Score': score,\n",
    "            'Folder location': location\n",
    "        })\n",
    "\n",
    "# Print the Dataframe result\n",
    "output_df = pd.DataFrame(Result)\n",
    "#print(output_df)\n",
    "\n",
    "# Use pandas to create an Excel file with XlsxWriter module with similarity coloring base on three conditions\n",
    "output_file = 'Excel_file/Result.xlsx'\n",
    "with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "    # write a dataframe into an excel file\n",
    "    output_df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "\n",
    "    # Get the workbook and worksheet object\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['Sheet1']\n",
    "    \n",
    "    # Determine the cell range for the Similarity Score column (row 2 to the last row)\n",
    "    num_rows = len(output_df)\n",
    "    cell_range = f'E2:E{num_rows + 1}'\n",
    "    \n",
    "    # Apply conditional formatting:\n",
    "    # Red for scores below 80% (< 0.8)\n",
    "    red_format = workbook.add_format({'bg_color': '#FFC7CE', 'font_color': '#9C0006'})\n",
    "    worksheet.conditional_format(cell_range, {\n",
    "        'type': 'cell',\n",
    "        'criteria': '<',\n",
    "        'value': 0.8,\n",
    "        'format': red_format\n",
    "    })\n",
    "    \n",
    "    # Orange for scores between 80% and 95% (0.8 to 0.95)\n",
    "    orange_format = workbook.add_format({'bg_color': '#FFEB9C', 'font_color': '#9C6500'})\n",
    "    worksheet.conditional_format(cell_range, {\n",
    "        'type': 'cell',\n",
    "        'criteria': 'between',\n",
    "        'minimum': 0.8,\n",
    "        'maximum': 0.95,\n",
    "        'format': orange_format\n",
    "    })\n",
    "    \n",
    "    # Green for scores 95% and above (>= 0.95)\n",
    "    green_format = workbook.add_format({'bg_color': '#C6EFCE', 'font_color': '#006100'})\n",
    "    worksheet.conditional_format(cell_range, {\n",
    "        'type': 'cell',\n",
    "        'criteria': '>=',\n",
    "        'value': 0.95,\n",
    "        'format': green_format\n",
    "    })\n",
    "\n",
    "    # Set column width for each column\n",
    "    worksheet.set_column('A:A', 8)\n",
    "    worksheet.set_column('B:B', 50)\n",
    "    worksheet.set_column('C:C', 50)\n",
    "    worksheet.set_column('D:D', 65)\n",
    "    worksheet.set_column('F:F', 30)\n",
    "    \n",
    "    # column E format is set to percentage instead, round to 2 decimal point\n",
    "    percentage_format = workbook.add_format({'num_format': '0.00%'})\n",
    "    worksheet.set_column('E:E', 14, percentage_format)\n",
    "\n",
    "\n",
    "# Get end time and total time taken\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total time: {total_time:.3f} seconds taken\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation content updated to: 1.14.5\n",
      "Annotation content updated to: 1.14.5\n",
      "Annotation content updated to: 1.14.5\n"
     ]
    }
   ],
   "source": [
    "# testing PDF editor with python (pip install PyMuPDF) d\n",
    "import fitz\n",
    "\n",
    "# this will be from the complier.py file (extracted from excel input file)\n",
    "saved_statement = \"ODB_2\"\n",
    "cur_statement = \"1.14.5\"\n",
    "\n",
    "# Open the PDF file\n",
    "doc = fitz.open(f'document/{saved_statement}.pdf')\n",
    "\n",
    "# loop over all pages in PDF file\n",
    "for page in doc:\n",
    "    # loop over all annotations\n",
    "    for annot in page.annots():\n",
    "        # check if annotation is a freetext annotation\n",
    "        if \"FreeText\" in annot.type:\n",
    "            # Update annotation text\n",
    "            annot.set_info(content=cur_statement, title=\"Oracle\")\n",
    "            annot.update()  # save annotation\n",
    "\n",
    "            print(f\"Annotation content updated to: {cur_statement}\")\n",
    "\n",
    "# Save the PDF file\n",
    "doc.save(f'document/{cur_statement}.pdf')\n",
    "doc.close()  # Close the document when done\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
